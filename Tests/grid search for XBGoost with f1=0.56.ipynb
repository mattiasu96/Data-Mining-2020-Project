{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport matplotlib.pyplot as plt\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":10,"outputs":[{"output_type":"stream","text":"/kaggle/input/traincsv/train.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/traincsv/train.csv')","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train\ntrain.info()","execution_count":12,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 621300 entries, 0 to 621299\nColumns: 136 entries, SITE_ID to kurt_temperature_alarms_prev14d\ndtypes: float64(118), int64(17), object(1)\nmemory usage: 644.7+ MB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport sklearn\nimport datetime as dt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.model_selection import train_test_split\n\ndata1 = train\ndata1['DATE'] = pd.to_datetime(data1['DATE'])\n\ny=data1['aircon_sum_target_next14d']\n\ndata1.drop(labels='aircon_sum_target_next14d', axis=1, inplace=True)\ndata1.drop(labels='SITE_ID', axis=1, inplace=True)\n\ndata2=data1 \n\ndata1['DATE']=data1['DATE'].map(dt.datetime.toordinal)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate and plot a synthetic imbalanced classification dataset\nfrom collections import Counter\nfrom sklearn.datasets import make_classification\nfrom matplotlib import pyplot\nfrom numpy import where\n\nX=data2\n\n#summarize class distribution\n\ncounter = Counter(y)\nprint(counter)","execution_count":14,"outputs":[{"output_type":"stream","text":"Counter({0: 617717, 1: 3583})\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit xgboost on an imbalanced classification dataset\nfrom numpy import mean\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nimport xgboost\nfrom xgboost import XGBClassifier\n# generate dataset\n#X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n#\tn_clusters_per_class=2, weights=[0.99], flip_y=0, random_state=7)\n# define model\nmodel = XGBClassifier()\n# define evaluation procedure\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n# evaluate model","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n# summarize performance\n#print('Mean ROC AUC: %.5f' % mean(scores))","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# estimate a value for the scale_pos_weight xgboost hyperparameter\nfrom sklearn.datasets import make_classification\nfrom collections import Counter\n\n\nestimate = 617717/3583\nprint('Estimate: %.3f' % estimate)","execution_count":17,"outputs":[{"output_type":"stream","text":"Estimate: 172.402\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# grid search positive class weights with xgboost for imbalance classification\nfrom numpy import mean\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom xgboost import XGBClassifier\n# generate dataset\nX=data1[['N_TRANSPORTED_SITES', 'kurt_equipment_alarms_prev14d',\n       'kurt_power_alarms_prev14d', 'aircon_sum_wo_prev14d',\n       'kurt_ge_alarms_prev14d', 'kurt_temperature_alarms_prev14d',\n       'kurt_fire/smoke_alarms_prev14d', 'skew_equipment_alarms_prev14d',\n       'aircon_sum_wo_prev7d', 'mean_rain_mm_f_next14d',\n       'mean_humidity_f_next14d', 'equipment_sum_alarms_prev14d',\n       'mean_temperature_f_next14d', 'temperature_sum_alarms_prev14d',\n       'skew_temperature_alarms_prev14d', 'mean_wind_speed_f_next14d',\n       'max_rain_mm_f_next14d', 'min_humidity_prev7d', 'mean_humidity_prev7d',\n       'max_humidity_f_next14d', 'min_humidity_f_next14d',\n       'mean_temperature_f_next7d', 'mean_humidity_f_next7d',\n       'max_rain_mm_prev7d', 'min_humidity_f_next7d',\n       'temperature_mean_persistance_prev7d', 'mean_pressure_f_next14d',\n       'mean_rain_mm_f_next7d', 'mean_wind_speed_prev7d',\n       'mean_wind_speed_f_next7d']]\n# define model\nmodel = XGBClassifier()\n# define grid\nweights = [ 1, 10, 25, 50, 75, 99, 1000, estimate]\nparam_grid = dict(scale_pos_weight=weights)\n# define evaluation procedure\ncv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=1)\n# define grid search\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='f1')\n# execute the grid search\ngrid_result = grid.fit(X, y)\n# report the best configuration\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n# report all configurations\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}